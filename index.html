<!DOCTYPE html>
<html>
<head>
    <title>Hypothesis Generation</title>
    <style>
        body {
            background-color: black;
            color: white;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .code-box {
            background-color: #222;
            padding: 10px;
            margin-bottom: 20px;
        }
        .code {
            font-family: monospace;
            color: white;
            white-space: pre;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Hypothesis Generation</h1>

        <div class="code-box">
            <h2>Code 1</h2>
            <div class="code">
                <code>
import pandas as pd
import numpy as np

# To read the data in the CSV file
data = pd.read_csv("hdata.csv")
print(data, "n")

# Making an array of all the attributes
d = np.array(data)[:,:-1]
print("n The attributes are: ", d)

# Segregating the target that has positive and negative examples
target = np.array(data)[:,-1]
print("n The target is: ", target)

# Training function to implement find-s algorithm
def train(c, t):
    for i, val in enumerate(t):
        if val == "Yes":
            specific_hypothesis = c[i].copy()
            break

    for i, val in enumerate(c):
        if t[i] == "Yes":
            for x in range(len(specific_hypothesis)):
                if val[x] != specific_hypothesis[x]:
                    specific_hypothesis[x] = '?'
                else:
                    pass

    return specific_hypothesis

# Obtaining the final hypothesis
print("n The final hypothesis is:", train(d, target))
                </code>
            </div>
        </div>

        <div class="code-box">
            <h2>Code 2</h2>
            <div class="code">
                <code>
import numpy as np
import pandas as pd

data = pd.read_csv('h2data.csv')
concepts = np.array(data.iloc[:,0:-1])
print("\nInstances are:\n", concepts)
target = np.array(data.iloc[:,-1])
print("\nTarget Values are: ", target)

def learn(concepts, target):
    specific_h = concepts[0].copy()
    print("\nInitialization of specific_h and general_h")
    print("\nSpecific Boundary: ", specific_h)
    general_h = [["?" for i in range(len(specific_h))] for i in range(len(specific_h))]
    print("\nGeneric Boundary: ", general_h)

    for i, h in enumerate(concepts):
        print("\nInstance", i+1, "is ", h)
        if target[i] == "yes":
            print("Instance is Positive ")
            for x in range(len(specific_h)):
                if h[x] != specific_h[x]:
                    specific_h[x] ='?'
                    general_h[x][x] ='?'

        if target[i] == "no":
            print("Instance is Negative ")
            for x in range(len(specific_h)):
                if h[x] != specific_h[x]:
                    general_h[x][x] = specific_h[x]
                else:
                    general_h[x][x] = '?'

        print("Specific Boundary after ", i+1, "Instance is ", specific_h)
        print("Generic Boundary after ", i+1, "Instance is ", general_h)
        print("\n")

    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]
    for i in indices:
        general_h.remove(['?', '?', '?', '?', '?', '?'])
    return specific_h, general_h

s_final, g_final = learn(concepts, target)

print("Final Specific_h: ", s_final, sep="\n")
print("Final General_h: ", g_final, sep="\n")
                </code>
            </div>
        </div>
        <div class="code-box">
            <h2>Code 3</h2>
            <div class="code">
                <code>
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

col_names=['pregnant','glucose','bp','shin','insulin','bmi','pedigree','age','label']
pima = pd.read_csv("pima-indians-diabetes.csv", header = None, names = col_names)
pima.head( )
pima.sample( )
pima.tail( )
#split dataset in feature and target variable
feature_cols=['pregnant','insulin','bmi','age','glucose','bp','pedigree']
X=pima[feature_cols]# Feature
Y=pima.label # target variable

# split dataset inti training set and test set
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3,random_state=1)# 70% training and 30% testing

# crete decision tree classifier object
clf = DecisionTreeClassifier()

# train decision tree classifier
clf =clf.fit(X_train,Y_train)

# predict the response for the test dataset
Y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, Y_pred))
</code>
</div>
</div>
        <div class="code-box">
            <h2>Code 3</h2>
            <div class="code">
                <code>
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

col_names=['pregnant','glucose','bp','shin','insulin','bmi','pedigree','age','label']
pima = pd.read_csv("pima-indians-diabetes.csv", header = None, names = col_names)
pima.head( )
pima.sample( )
pima.tail( )
#split dataset in feature and target variable
feature_cols=['pregnant','insulin','bmi','age','glucose','bp','pedigree']
X=pima[feature_cols]# Feature
Y=pima.label # target variable

# split dataset inti training set and test set
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3,random_state=1)# 70% training and 30% testing

# crete decision tree classifier object
clf = DecisionTreeClassifier()

# train decision tree classifier
clf =clf.fit(X_train,Y_train)

# predict the response for the test dataset
Y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, Y_pred))
</code>
</div>
</div>
<div class="code-box">
    <h2>Code 4</h2>
    <div class="code">
        <code>
            # Load libraries
            import pandas as pd
            
            # Import Decision Tree Classifier
            from sklearn.tree import DecisionTreeClassifier
            
            # Import train_test_split function
            from sklearn.model_selection import train_test_split
            
            # Import scikit-learn metrics module for accuracy calculation
            from sklearn import metrics
            
            col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']
            
            # Load dataset
            pima = pd.read_csv("pima-indians-diabetes.csv", header=None, names=col_names)
            pima.head()
            
            # Split dataset into features and target variable
            feature_cols = ['pregnant', 'insulin', 'bmi', 'age', 'glucose', 'bp', 'pedigree']
            
            X = pima[feature_cols]  # Features
            y = pima.label  # Target variable
            
            # Split the dataset into the training set and test set
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)  # 70% training and 30% test
            
            # Create Decision Tree classifer object
            clf = DecisionTreeClassifier()
            
            # Train Decision Tree Classifer
            clf = clf.fit(X_train, y_train)
            
            # Predict the response for the test dataset
            y_pred = clf.predict(X_test)
            
            # Model Accuracy, how often is the classifier correct?
            print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
            
            from sklearn.tree import export_graphviz
            from six import StringIO
            from IPython.display import Image
            import pydotplus
            
            dot_data = StringIO()
            export_graphviz(clf, out_file=dot_data,
                            filled=True, rounded=True,
                            special_characters=True, feature_names=feature_cols, class_names=['0', '1'])
            graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
            graph.write_png('diabetes.png')
            Image(graph.create_png())
            
            # Create Decision Tree classifer object with entropy as the criterion and max_depth of 3
            clf = DecisionTreeClassifier(criterion="entropy", max_depth=3)
            
            # Train Decision Tree Classifer
            clf = clf.fit(X_train, y_train)
            
            # Predict the response for the test dataset
            y_pred = clf.predict(X_test)
            
            # Model Accuracy, how often is the classifier correct?
            print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
            <div class="code-box">
        </code>
    </div>
</div>
 <div class="code-box">
    <h2>Code 4</h2>
    <div class="code">
        <code>
            import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X, y = make_blobs(n_samples=500, n_features=2, centers=4, cluster_std=1.5, random_state=4)

plt.style.use('seaborn')
plt.figure(figsize=(10, 10))
plt.scatter(X[:, 0], X[:, 1], c=y, marker='*', s=100, edgecolors='black')
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

knn5 = KNeighborsClassifier(n_neighbors=5)
knn1 = KNeighborsClassifier(n_neighbors=1)

knn5.fit(X_train, y_train)
knn1.fit(X_train, y_train)

y_pred_5 = knn5.predict(X_test)
y_pred_1 = knn1.predict(X_test)

print("Accuracy with k=5:", accuracy_score(y_test, y_pred_5) * 100)
print("Accuracy with k=1:", accuracy_score(y_test, y_pred_1) * 100)
        </code>
    </div>
 </div>

    </div>
</body>
</html>
